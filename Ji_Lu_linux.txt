11.14 

一、安装QGC

	1、官网有详细的教程
	
	    Before installing QGroundControl for the first time:

	    1、On the command prompt enter:

		    sudo usermod -a -G dialout $USER
		    sudo apt-get remove modemmanager -y
		    sudo apt install gstreamer1.0-plugins-bad gstreamer1.0-libav gstreamer1.0-gl -y
		    sudo apt install libqt5gui5 -y
		    sudo apt install libfuse2 -y

	    2、Logout and login again to enable the change to user permissions.

	    To install QGroundControl:

	    1）Download QGroundControl.AppImage.
	    2）Install (and run) using the terminal commands:

		    chmod +x ./QGroundControl.AppImage
		    ./QGroundControl.AppImage  (or double click)

	*注：按照官网的教程走下来之后出现报错：
	error while loading shared libraries: libSDL2-2.0.so.0: cannot open shared object file: No such file or directory

	解决办法：安装依赖项
	sudo apt-get install espeak libespeak-dev libudev-dev libsdl2-dev
	


	2、取出飞控SD卡，往里推一下，用读卡器将频率调成200Hz（默认50Hz）：未完成，没有SD卡读卡器。。。

	3、重新安装固件

	进入深蓝学院官网下载压缩包，解压后有1.11固件，选择自定义固件，选择解压后固件的地址，选择固件后系统自动烧录


	4、配置无人机和遥控器
	
		接受机对码：说明书描写不充分

		没有完成对码！无法对遥控器进行校正，甚至连之前的左右相反的方向都没了，惨。。。

	目前存在问题，而且问题不少！！！

	注：Ubuntu 修改用户密码方法详解
	
	$ passwd xcs
	修改后的密码要比原本的密码更加复杂，因此我没有修改！！

	5、根据之前记载的笔记安装ros，这里不再记录
	附带参考链接：http://t.csdn.cn/uu7pu

----------------------------------------------------------------------------------------------------------------------------------
11.15
	
一、关于个github本地上传与连接
	
	要关联一个远程库，使用命令
	git remote add origin git@server-name:path/repo-name.git；

	关联一个远程库时必须给远程库指定一个名字，origin是默认习惯命名；

	关联后，使用命令
	git push -u origin master第一次推送master分支的所有内容；

	此后，每次本地提交后，只要有必要，就可以使用命令
	git push origin master推送最新修改；

	*删除远程库
	如果添加的时候地址写错了，或者就是想删除远程库，可以用git remote rm <name>命令。使用前，建议先用git remote -v查看远程库信息：

	$ git remote -v
	origin	git@github.com:97latter/backupthesis.git (fetch)
	origin	git@github.com:97latter/backupthesis.git (push)

	然后，根据名字删除，比如删除origin：
	$ git remote rm origin
	此处的“删除”其实是解除了本地和远程的绑定关系，并不是物理上删除了远程库。远程库本身并没有任何改动。要真正删除远程库，需要登录到GitHub，在后台页面找到删除按钮再删除。
	
二、ego-planner仿真

	
	参考：http://t.csdn.cn/qTs0L

三、安装ssh并给记载计算机设置别名

	sudo apt install net-tools 
	
	查看ip地址：
	ifconfig
	
	给记载计算机设置别名：
	sudo gedit /etc/hosts
	在最后，添加
	192.168.31.6	lzj_tx2
	
	ping lzj_tx2可以ping通：
	PING lzj_tx2 (192.168.31.6) 56(84) bytes of data.
	64 bytes from lzj_tx2 (192.168.31.6): icmp_seq=1 ttl=64 time=15.5 ms
	64 bytes from lzj_tx2 (192.168.31.6): icmp_seq=2 ttl=64 time=10.9 ms
	64 bytes from lzj_tx2 (192.168.31.6): icmp_seq=3 ttl=64 time=10.8 ms
	64 bytes from lzj_tx2 (192.168.31.6): icmp_seq=4 ttl=64 time=40.8 ms

	ssh 用户名@别名：
	ssh lzj@lzj_tx2  连接记载计算机的终端

	
------------------------------------------------------------------------------------------
11.16


一、安装VINS，调试无人机起飞，仿真模拟；


二、安装PX4，搭建仿真环境
	
	1、PX4源码下载（这里下载的是v1.12.3版本的PX4）
	git clone -b v1.12.3 https://github.com/PX4/PX4-Autopilot.git --recursive

	2、安装依赖
	bash ./PX4-Autopilot/Tools/setup/ubuntu.sh
	
	3、编译
	cd PX4-Autopilot
	make px4_sitl_default gazebo

	4、设置环境变量
	（1）运行gedit ~/.bashrc 打开.bashrc文件
	gedit ~/.bashrc
	
	（2）把下面代码粘贴复制到该文件的最后面
	source ~/PX4-Autopilot/Tools/setup_gazebo.bash ~/PX4-Autopilot/ ~/PX4-Autopilot/build/px4_sitl_default
	export ROS_PACKAGE_PATH=$ROS_PACKAGE_PATH:~/PX4-Autopilot
	export ROS_PACKAGE_PATH=$ROS_PACKAGE_PATH:~/PX4-Autopilot/Tools/sitl_gazebo

	（3）完成之后记得 source ~/.bashrc 一下
	source ~/.bashrc
	
	5、运行launch文件
	cd ~/ PX4-Autopilot
	roslaunch px4 mavros_posix_sitl.launch
	
	6、检查与mavros连接是否正常
	rostopic echo /mavros/state


-------------------------------------------------------------------------------------
11.17


一、强化学习路线
	
入门思路：
（1）认识各种强化学习词汇，了解强化学习各种算法发展买了，建立整体框架概念；
	
（2）学习基本的理论，最好中文，便于理解透彻；

（3）上手写代码，做出视觉demo，形成对强化学习算法的直观感受；

（4）系统学习基础理论

参考：强化学习怎么入门好？ - 花半楼的回答 - 知乎
https://www.zhihu.com/question/277325426/answer/816094591


二、PX4继续仿真

1、报错

	CMake Error at CMakeLists.txt:34 (find_program):
  Could not find px4 using the following names:
	-- Configuring incomplete, errors occurred!
	See also "/home/xcs/PX4_Firmware/build/px4_sitl_default/build_gazebo/CMakeFiles/CMakeOutput.log".
	See also "/home/xcs/PX4_Firmware/build/px4_sitl_default/build_gazebo/CMakeFiles/CMakeError.log".
	[135/740] Building CXX object msg/CMakeFiles/uorb_msgs.dir/topics_sources/position_controller_landing_status.cpp.o
	FAILED: external/Stamp/sitl_gazebo/sitl_gazebo-configure /home/xcs/PX4_Firmware/build/px4_sitl_default/external/Stamp/sitl_gazebo/sitl_gazebo-configure 
	cd /home/xcs/PX4_Firmware/build/px4_sitl_default/build_gazebo && /home/xcs/cmake-3.24.3-linux-x86_64/bin/cmake -DCMAKE_INSTALL_PREFIX=/usr/local -DSEND_VISION_ESTIMATION_DATA=ON -GNinja /home/xcs/PX4_Firmware/Tools/sitl_gazebo && /home/xcs/cmake-3.24.3-linux-x86_64/bin/cmake -E touch /home/xcs/PX4_Firmware/build/px4_sitl_default/external/Stamp/sitl_gazebo/sitl_gazebo-configure
	[145/740] Building CXX object msg/CMakeFiles/uorb_msgs.dir/topics_sources/orb_test_large.cpp.o
	ninja: build stopped: subcommand failed.
	Makefile:198: recipe for target 'px4_sitl_default' failed
	make: *** [px4_sitl_default] Error 1


解决办法：重装gazebo9-----(无效)



	

参考链接：
https://classic.gazebosim.org/tutorials?tut=install_ubuntu&cat=install


			
2、运行gazebo报错：
gazebo: symbol lookup error: /usr/lib/x86_64-linux-gnu/libgazebo_common.so.9: undefined symbol: _ZN8ignition10fuel_tools12ClientConfig12SetUserAgentERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE


解决办法：

运行一下：sudo apt-get upgrade


------------------------------------------------------------------------------------------------------------

11.21

一、天津市公务员报名考试：
http://rsks.hrss.tj.gov.cn/ks/index.do?method=select

二、解决之之前“make px4_sitl_Default gazebo”报错的问题：

	重装cmake，这次安装的是cmake-3.17.2-Linux-x86_64,安装过程与之前安装cmake相同：
	
	1）查看当前版本
	cmake --version
	
	2）在cmake官网下载，我下载的是cmake-3.17.2-Linux-x86_64
	cmake官网：https://cmake.org/download/
	（注：再此步骤之前，还有一步卸载cmake，由于我安装了ros，提示会卸载许多与ros相关的cmake文件，可能会导致ros无法使用，所以跳过卸载的过程直接下载更好版本cmake。）
	
	3）安装cmake

	将cmake-3.17.2-Linux-x86_64解压并提取出来
	
	由于安装了ros跳过了第二步，所以先找到cmake路径，将原来版本的cmake执行文件删除
	which cmake
	cd /usr/bin/
	sudo rm cmake
		
	注意：
	01. cmake-3.17.2-Linux-x86_64压缩包里的文件是已经编译过的，解压就可以用！
	02. cmake各个版本解压文件下载地址：https://cmake.org/files/


	4）建立软链接
	sudo ln -s /home/xcs/cmake-3.17.2-Linux-x86_64/bin/cmake /usr/bin/cmake

参考链接：https://github.com/robin-shaun/XTDrone/issues/18


三、PX4仿真报错

	1、运行‘roslaunch px4 mavros_posix_sitl.launch’后出现：
	RLException: [mavros_posix_sitl.launch] is neither a launch file in package [px4] nor is [px4] a launch file name
	The traceback for the exception was written to the log file
	
	解决办法：
	在终端输入
	source ~/PX4_Firmware/Tools/setup_gazebo.bash ~/PX4_Firmware/ ~/PX4_Firmware/build/px4_sitl_default
	export ROS_PACKAGE_PATH=$ROS_PACKAGE_PATH:~/PX4_Firmware
	export ROS_PACKAGE_PATH=$ROS_PACKAGE_PATH:~/PX4_Firmware/Tools/sitl_gazebo
	
	重新执行‘roslaunch px4 mavros_posix_sitl.launch’指令

参考链接

	2、重新运行上述指令后又出现新的报错：
	Resource not found: gazebo_ros
	ROS path [0]=/opt/ros/melodic/share/ros
	ROS path [1]=/opt/ros/melodic/share
	ROS path [2]=/home/xcs/PX4_Firmware
	ROS path [3]=/home/xcs/PX4_Firmware/Tools/sitl_gazebo
	The traceback for the exception was written to the log file

	解决办法：
	根据报错的提示，缺少gazebo_ros  ，直接安装缺失的gazebo：
	sudo apt-get install ros-melodic-gazebo-ros-pkgs ros-melodic-gazebo-ros-control

参考链接：http://t.csdn.cn/LyJ4z
	
四、查看ros tf tree
	
	roscore
	rosrun rqt_plot rqt_plot

五、git push origin master 失败

	原因：
	Git仓库中已经有一部分代码，所以它不允许你直接把你的代码覆盖上去。
	远程仓库和本地仓库存在差异。
	一般都是因为你在码云创建的仓库有ReadMe文件，而本地没有，造成本地和远程的不同步，
	解决方法：

	解决方法：同步
	
	1、git pull origin master --allow-unrelated-histories //把远程仓库和本地同步，消除差异
	2、重新add和commit相应文件
	3、git push origin master
	4、此时就能够上传成功了

参考链接：https://www.cnblogs.com/qingheshiguang/p/14777557.html


六、ego-planner三位运动规划仿真报错  （待解决）
	
	CMake Error at /opt/ros/melodic/share/catkin/cmake/catkinConfig.cmake:83 (find_package):
	  Could not find a package configuration file provided by "quadrotor_msgs"
	  with any of the following names:

	    quadrotor_msgsConfig.cmake
	    quadrotor_msgs-config.cmake
	
	解决办法：应该是缺少某些安装包，这个问题之前遇到过，等找找记得笔迹；

--------------------------------------------------------------------------------------

七、避障实验仿真



-----------------------------------------------------------------------------------------

11.23


一、gazebo+QGC联动仿真

	1、配置仿真平台
	依次进行gazebo安装（仿真平台）、mavros安装（无人机通信模块）、px4配置、地面站QGroundControl安装。
	
	2、创建工作空间与功能包，写入飞行代码
	
	1）创建工作空间
	#创建工作空间
	midir catkin_ws/
	 
	cd catkin_ws/
	 
	midir src
	 
	cd src/
	 
	catkin_init_workspace
	 
	#编译工作空间
	cd..
	 
	catkin_make
	 
	#设置环境变量
	source devel/setup.bash
	 
	#检查环境变量
	echo $ROS_PACKAGE_PATH

	2）创建功能包（功能包是放在工作空间src文件夹中实现具体功能的特殊文件夹，是放置ROS源码的最小单元）	
	#创建功能包(offboard_sin是功能包名)
	cd ~/catkin_ws/src
	 
	catkin_create_pkg offboard_sin std_msgs rospy roscpp
	 
	#编译功能包
	cd ~/catkin_ws
	 
	catkin_make
	 
	source ~/catkin_ws/devel/setup.bash

	3）写入飞行代码（在功能包的src路径下创建offboard_sin_node.cpp文件，并写入如下沿着sin路径飞行的代码 ）
		/**
	 * @file offb_node.cpp
	 * @brief Offboard control example node, written with MAVROS version 0.19.x, PX4 Pro Flight
	 * Stack and tested in Gazebo SITL
	 */
	 
	#include <ros/ros.h>
	#include <geometry_msgs/PoseStamped.h>
	#include <geometry_msgs/Vector3.h>
	#include <mavros_msgs/CommandBool.h>
	#include <mavros_msgs/SetMode.h>
	#include <mavros_msgs/State.h>
	 
	#define PI acos(-1)
	 
	mavros_msgs::State current_state;
	geometry_msgs::PoseStamped current_position;
	 
	void state_cb(const mavros_msgs::State::ConstPtr& msg){
	    current_state = *msg;
	}
	void getpointfdb(const geometry_msgs::PoseStamped::ConstPtr& msg){
	    ROS_INFO("x: [%f]", msg->pose.position.x);
	    ROS_INFO("y: [%f]", msg->pose.position.y);
	    ROS_INFO("z: [%f]", msg->pose.position.z);
	    current_position = *msg;
	}
	 
	int main(int argc, char **argv)
	{
	    ros::init(argc, argv, "offb_node");
	    ros::NodeHandle nh;
	 
	    ros::Subscriber state_sub = nh.subscribe<mavros_msgs::State>
		    ("mavros/state", 10, state_cb);
		    
	    ros::Subscriber get_point = nh.subscribe<geometry_msgs::PoseStamped>
		    ("mavros/local_position/pose", 10, getpointfdb);
		    
	    ros::Publisher local_pos_pub = nh.advertise<geometry_msgs::PoseStamped>
		    ("mavros/setpoint_position/local", 10);
	    ros::ServiceClient arming_client = nh.serviceClient<mavros_msgs::CommandBool>
		    ("mavros/cmd/arming");
	    ros::ServiceClient set_mode_client = nh.serviceClient<mavros_msgs::SetMode>
		    ("mavros/set_mode");
	 
	    //the setpoint publishing rate MUST be faster than 2Hz
	    ros::Rate rate(20.0f);
	 
	    // wait for FCU connection
	    while(ros::ok() && !current_state.connected){
		ros::spinOnce();
		rate.sleep();
	    }
	 
	    geometry_msgs::PoseStamped pose;
	    pose.pose.position.x = 0;
	    pose.pose.position.y = 0;
	    pose.pose.position.z = 3;
	    
	    
	    
	 
	    //send a few setpoints before starting
	    for(int i = 100; ros::ok() && i > 0; --i){
		local_pos_pub.publish(pose);
		ros::spinOnce();
		rate.sleep();
	    }
	 
	    mavros_msgs::SetMode offb_set_mode;
	    offb_set_mode.request.custom_mode = "OFFBOARD";
	 
	    mavros_msgs::CommandBool arm_cmd;
	    arm_cmd.request.value = true;
	 
	    ros::Time last_request = ros::Time::now();
	 
	    while(ros::ok()){
		if( current_state.mode != "OFFBOARD" &&
		    (ros::Time::now() - last_request > ros::Duration(5.0f))){
		    if( set_mode_client.call(offb_set_mode) &&
		        offb_set_mode.response.mode_sent){
		        ROS_INFO("Offboard enabled");
		    }
		    last_request = ros::Time::now();
		} else {
		    if( !current_state.armed &&
		        (ros::Time::now() - last_request > ros::Duration(5.0f))){
		        if( arming_client.call(arm_cmd) &&
		            arm_cmd.response.success){
		            ROS_INFO("Vehicle armed");
		        }
		        last_request = ros::Time::now();
		    }
		}
		
		if((abs(current_position.pose.position.x-pose.pose.position.x)<0.5f)&&(abs(current_position.pose.position.y-pose.pose.position.y)<0.5f)&&(abs(current_position.pose.position.y-pose.pose.position.y)<0.5f))
		{
		    pose.pose.position.x += 5;
		    pose.pose.position.y = 20*sin(pose.pose.position.x/40*PI);
		    pose.pose.position.z = 3;
		}
	 
		local_pos_pub.publish(pose);
	 
		ros::spinOnce();
		rate.sleep();
	    }
	 
	    return 0;
	}
	
	
	4）修改CMakeLists.txt文件，在最后加入下面两行
	add_executable(offboard_node src/offboard_node.cpp)
	target_link_libraries(offboard_node ${catkin_LIBRARIES})
	
	最后，回到catkin_ws文件夹编译：
	catkin build
	source devel/setup.bash
	
	
	
	3、实现飞行仿真
	
	打开终端，输入：
	roslaunch px4 mavros_posix_sitl.launch
	
	此launch文件会打开gazebo启动无人机模型并建立好mavros通信

	同时，打开QGroundControl，其会自动与你gazebo里的无人机进行通信连接
	cd Downloads
	./QGroundControl.AppImage

	然后打开新终端，进入catkin_ws,输入：
	rosrun offboard_sin offboard_sin_node
 
	#rosrun+功能包+功能包内节点文件

	 至此，第一次简单的无人机飞行仿真结束。

---------------------------------------------------------------

11.25
ubuntu:	 
服务器IP：192.168.31.163
服务器用户名：galaxy

<<<<<<< HEAD

	11.25

	
	
=======
windows:
   本地链接 IPv6 地址. . . . . . . . : fe80::6300:d670:b186:e66b%15
   IPv4 地址 . . . . . . . . . . . . : 192.168.31.64
   子网掩码  . . . . . . . . . . . . : 255.255.255.0
   默认网关. . . . . . . . . . . . . : 192.168.31.1

服务器用户名：galaxy
设备名称：Galaxy-RTX-2070
>>>>>>> b0177a1771f833574df9548880a09002d16caf41


---------------------------------------------------------------------
11.26

一、caktin build 编译ego-planner报错

	Errors  << multi_map_server:make /home/xcs/catkin_ws/logs/multi_map_server/build.make.001.log                                             
	/usr/bin/ld: cannot find -lpose_utils
	collect2: error: ld returned 1 exit status
	make[2]: *** [/home/xcs/catkin_ws/devel/.private/multi_map_server/lib/multi_map_server/multi_map_visualization] Error 1
	make[1]: *** [CMakeFiles/multi_map_visualization.dir/all] Error 2
	make: *** [all] Error 2

暂时未解决


二、硕士毕业论文写作建议：

	1、论文评审三个纬度：功劳+苦劳+态度

		1）功劳：论文深度（难度）。是否发表了高水平小论文，一般发表了1～2篇高水平小论文，表明大论文有期刊评论人把关，没什么大问题。

		2）苦劳：工作量大小。论文没有深度但是工作量大也行（实验开展时常，仿真数据量大）

		3）态度：规范性。包括：论文排版、参考文献引用，错别字，错误标点符号（半角全角）。写好论文后，最好打印出来，逐字逐句用铅笔修改，避免第机错误，再给导师修改。

		** 不要把半成品（通篇低级错误）的论文发给老师改！！

		论文评阅：功劳（论文深度）是关键、苦劳（数据量）是加分、态度是关键。还有就是重复率问题，不要被同宿舍同学抄袭

	2、大论文基本构成：
		
		题目
		
		摘要

		第一章 绪论

		第二～四章（最好对应三篇小论文，尽量多发论文，保证每一章对应一篇高质量论文；对实验性论文，第二章可以为实验数据准备）

		第五章 结论

	误区：论文越长越好，拼命凑字数

	好的论文：逻辑清晰、论证详实、字数简短（要求4万字就写4万字），围绕一～三个创新点，把故事将清楚就可以了

	3、每部分的写法：

		1) 题目：不要小题大做，不要大题小作
	
		例如：新冠肺炎研究；  太大      新冠肺炎预测模型研究；小一点	大城市新冠肺炎预测研究--以广州xx区为例，更聚焦

		2)题目要包括：方法+目的
		
		基于大数据深度学习的大城市新冠肺炎预测研究--以广州xx区为例
		
		3）摘要写作三种形式：
		 1、背景+问题；2、研究综述；3、研究主要成果

		 1、背景+问题；2、研究综述；3、首先、其次、然后

		 1、背景+问题；2、研究综述；3、分别介绍三个主要章节内容

		4）正文写作
		正文的每一章相当于一篇独立小论文，因此只要掌握小论文正确方法，就能把正文写好；

	4、如何正确水字数
		基于大数据深度学习的大城市新冠肺炎预测研究--以广州xx区为例		

		1）加方法；例如：与传统bp神经网络、SVM等预测方法结果进行对比；

		2）加案例；例如：以广州二个区为例或广州与武汉案例间对比结果差异；

		3）加影响因素或变量；假期与非假期预测规律对比
		
		总之，在无法增加论文深度情况下，尽量加大有意义的工作量。


三、Ubuntu系统PDF阅读器  okular

	1、安装：sudo apt-get install okular

	2、注释：F6


------------------------------------------------------------------------------------------------------

11.28

一、还是catkin_ws编译ego-planner问题

	修改编译方式：使用catkin_make编译,出现报错：
	[ 88%] Linking CXX shared library /home/xcs/catkin_ws/devel/lib/libgazebo_ros_bumper.so
	In file included from /home/xcs/catkin_ws/src/ego_planner/Utils/rviz_plugins/src/multi_probmap_display.cpp:53:0:
	/home/xcs/catkin_ws/src/ego_planner/Utils/rviz_plugins/src/multi_probmap_display.h:40:10: fatal error: multi_map_server/MultiOccupancyGrid.h: No such file or directory
	 #include <multi_map_server/MultiOccupancyGrid.h>
          ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
	解决方法：
	链接：https://pan.baidu.com/s/1gw6ytOEUZeEbxhkOwsnL_g
	提取码：jm8s
	把这四个文件放在/devel/include/multi_map_server/下
	或放在/src/uav_simulator/Utils/multi_map_server/include/multi_map_server/下

参考链接：http://t.csdn.cn/plY0L

二、编译VINS-Fusion报错

	CMake Error at VINS-Fusion/camera_models/CMakeLists.txt:19 (find_package):
	  By not providing "FindCeres.cmake" in CMAKE_MODULE_PATH this project has
	  asked CMake to find a package configuration file provided by "Ceres", but
	  CMake did not find one.

	  Could not find a package configuration file provided by "Ceres" with any of
	  the following names:

	    CeresConfig.cmake
	    ceres-config.cmake
	
	原因：缺少crers包

	解决方法：安装ceres包

	sudo apt install libceres-dev

参考：http://t.csdn.cn/jkkuQ
	
	

------------------------------------------------------

11.29

一、实现自建障碍物控制空间，gazebo

	命名为model2.gazebo

	替换掉原来的launch文件中的gazebo

二、已经完成避障实验仿真，前期准备具体过程如下

	1、首先建好自己的障碍物实验场景，命名为my_model3.world.
	
	2、修改indoor1.launch文件夹中world的名字为上面提到的my_model3.world,并且将my_model3.world文件移动到PX4_Firmware/Tools/sitl_gazebo/worlds路径下；
	
	3、修改～/catkin_ws/src/ego_planner/plan_manage/launch/sigle_uav.launch中的目的地，将原来的左臂地址注释：

				<!-- 原目的地，已注释
				<arg name="target_x" value="0"/>
				<arg name="target_y" value="-20"/>
				<arg name="target_z" value="1.0"/>

				替换为：

				        <arg name="target_x" value="5.2"/>
					<arg name="target_y" value="-13"/>
					<arg name="target_z" value="1.0"/>

	4、在~/catkin_ws/src/ego_planner/plan_manage/launch/run_in_xtdrone.launch中，可以选择多个waypoint：

	
		    <arg name="point_num" value="1" />

		    <arg name="point0_x" value="$(arg target_x)" />
		    <arg name="point0_y" value="$(arg target_y)" />
		    <arg name="point0_z" value="$(arg target_z)" />

		    <arg name="point1_x" value="6.0" />
		    <arg name="point1_y" value="0.0" />
		    <arg name="point1_z" value="1.5" />

		    <arg name="point2_x" value="8.0" />
		    <arg name="point2_y" value="-8.0" />
		    <arg name="point2_z" value="1.5" />

		    <arg name="point3_x" value="0.0" />
		    <arg name="point3_y" value="-15.0" />
		    <arg name="point3_z" value="1.0" />

		    <arg name="point4_x" value="-15.0" />
		    <arg name="point4_y" value="0.0" />
		    <arg name="point4_z" value="1.0" />


	5通过修改飞行类型，可以选择1，从而通过RVIZ中的2DNav Goal来设置目的地。

		    <!-- 1: use 2D Nav Goal to select goal  -->
		    <!-- 2: use global waypoints below  -->
		    <arg name="flight_type" value="2" />


三、ego-planner具体仿真过程如下：

	1、首先编译ego_planner:
		
		cp -r  ~/XTDrone/motion_planning/3d/ego_planner ~/catkin_ws/src/
		cd ~/catkin_ws/
		catkin_make #或catkin build ego_planner

	2、启动仿真：
		ego_planner需要输入深度图+相机位姿或是点云，深度图来源与realsense_camrea，
		（记得把indoot1.launch的iris_stereo_camera换成iris_realsense_camera）,相机位姿由VINS-Fusion计算得到。
		
	**下面是VINS-Fusion仿真过程：
	使用双目+IMU

	3、VINS-Fusion编译：

		cp -r ~/XTDrone/sensing/slam/vio/VINS-Fusion ~/catkin_ws/src/
		mkdir ~/catkin_ws/scripts/
		cp ~/XTDrone/sensing/slam/vio/xtdrone_run_vio.sh ~/catkin_ws/scripts/
		cd ~/catkin_ws
		catkin_make #或catkin build，取决于您的编译工具

	4、VINS-Fusion仿真：

		注意把EKF设置为视觉定位，设置过程如下：

			注：PX4默认使用的EKF配置为融合GPS的水平位置与气压计高度。如果我们想使用视觉定位，就需要把修改配置文件。
			● 注意，此修改意味着EKF融合来自mavros/vision_pose/pose的数据，并不是修改完无人机就可以视觉定位了，
			需要相关程序提供mavros/vision_pose/pose的数据，相关程序包括视觉SLAM、激光SLAM和获取Gazebo真值等。
			如果没有额外的视觉数据，想要飞行必须改回基于GPS和气压计的定位。

			1）输入以下命令，打开对应文件：
			gedit ~/PX4_Firmware/ROMFS/px4fmu_common/init.d-posix/rcS

			2）在原文件中对应位置，将语句改为如下所示：
				# GPS used
				#param set EKF2_AID_MASK 1
				# Vision used and GPS denied
				param set EKF2_AID_MASK 24

				# Barometer used for hight measurement
				#param set EKF2_HGT_MODE 0
				# Barometer denied and vision used for hight measurement
				param set EKF2_HGT_MODE 3

			3）重启仿真前，需要删除上一次记录在虚拟eeprom中的参数文件，否则仿真程序会读取该参数文件，导致本次rcS的修改不能生效：
			rm ~/.ros/eeprom/parameters*
			rm -rf ~/.ros/sitl*

	5、启动仿真程序，注意laucnh文件中使用iris_stereo_camera.sdf:
		roslaunch px4 indoor1.launch


	6、启动VINS-Fusion，注意其订阅的话题是iris_0de ,如果要环岛别的vehicle，需要对应修改。另外临时文件存储路径也要对应修改。
		输入：gedit ~/catkin_ws/src/VINS-Fusion/config/xtdrone_sitl/px4_sitl_stereo_imu_config.yaml

		对应需要修改的语句如下：
		
		imu_topic: "/iris_0/imu_gazebo"
		image0_topic: "/iris_0/stereo_camera/left/image_raw"
		image1_topic: "/iris_0/stereo_camera/right/image_raw"
		output_path: "/home/robin/catkin_ws/vins_output"
		.
		.
		.
		pose_graph_save_path: "/home/robin/catkin_ws/vins_output/pose_graph/"  # save and load path

	然后输入：
		cd ~/catkin_ws
		bash scripts/xtdrone_run_vio.sh

	VINS-Fusion就启动了

	7、由于VINS-Fusion发布的是Odometry类型的话题，因此需要将其对应转为PX4所需要的话题
		cd ~/XTDrone/sensing/slam/vio
		python vins_transfer.py iris 0
			
	8、这是PX4仿真终端出现如下所示输出，代表视觉信息融合成功

		INFO  [ecl/EKF] 1213644000: reset position to ev position
		INFO  [ecl/EKF] 1213644000: commencing external vision position fusion
		INFO  [ecl/EKF] 1213644000: commencing external vision yaw fusion
			
	9、然后建立通讯：
		cd ~/XTDrone/communication
		python multirotor_communication.py iris 0


	10、键盘控制无人机起飞即可：
		cd ~/XTDrone/control/keyboard
		python multirotor_keyboard_control.py iris 1 vel

	**至此，电脑上的VINS-Fusion仿真完成，以下还有一步在无人机上实现的VIO初始化，暂时没有实现：
		VINS-Fusion的双目+IMU可以在静止条件下完成初始化，因此不用额外考虑。
		但单目+IMU以及ORBSLAM3的单目/双目+IMU均需要在运动中初始化，在实物系统中，我们可以用手晃一晃飞机实现初始化，
		而仿真中必须起飞才能让无人机运动，但PX4的offboard模式如果没有定位数据，又无法起飞，这就造成了矛盾。
		因此仿真里只能用Gazebo真值给PX4定位，然后在飞行过程中初始化VIO，VIO的输出只用于测试精度，并不实际给无人机定位用。
	
	11、在完成上述的VINS-Fusion启动仿真之后，将无人机起飞悬停，关闭键盘控制

	12、转换相机位姿的坐标系方向：
		cd ~/XTDrone/motion_planning/3d
		python ego_transfer.py iris 0

	13、启动rviz：
		cd ~/XTDrone/motion_planning/3d
		rviz -d ego_rviz.rviz
	14、启动ego_planner：
		roslaunch ego_planner single_uav.launch 

	注意：目的地的修改以及waypoint的选择均可以修改，上面的前夕准备已经介绍，不再赘述。
	至此，避障仿真实验完成。

	
			
	
	

参考：

1、https://www.yuque.com/xtdrone/manual_cn/building_editor

2、https://www.yuque.com/xtdrone/manual_cn/3d_motion_planning

3、https://www.yuque.com/xtdrone/manual_cn/3d_motion_planning

4、https://www.yuque.com/xtdrone/manual_cn/vio#luwyy

5、https://www.yuque.com/xtdrone/manual_cn/ekf_settings

6、https://gitee.com/robin_shaun/XTDrone/tree/master/sensing/slam/vio/VINS-Fusion

7、https://www.yuque.com/xtdrone/manual_cn/basic_config



四、XML 文件注释

	1、第一种（单行）：

 	<!--  注释内容   -->
 
	2、第二种（多行）：

	
	<!--      
		注释内容（无其他注释符）
	-->

	3、第三种（多行）：
	
	
	<![CDATA[   
		注释内容（包含其他注释符）
	]]>
	

参考：http://t.csdn.cn/ATMcl


-------------------------------------------------------------------

11.30

今天争取完成环境中添加移动的人或者车，以及稠密点云仿真

晚上在windows再试试校准电调
参考：http://t.csdn.cn/HFFlc	



添加路灯：lamp post

添加人：actor

一、Actor行人插件配置

	1、安装插件：
	
	cp -r ~/XTDrone/sitl_config/gazebo_plugin/gazebo_ros_actor_plugin ~/catkin_ws/src/
	cd ~/catkin_ws
	catkin_make #或catkin build

	2、启动robocup.launch，此时会看到world中有6个actor禁止不动
	
	roslaunch px4 robocup.launch

	3、通过修改actor的init_pose标签，可以更改actor的初始位置。
	可以通过脚本动态调节actor的位置

	cd ~/XTDrone/control/actor
	bash control_actors.sh


二、VINS-Fusion+RTABMap的三维稠密重建

	之前教程介绍的双目SLAM和VIO获得的都是稀疏点云，无法运用于避障与运动规划。

	(仿真效果一般，经常卡死...)

三、安装飞行日志分析软件PlotJuggler（时序分析软件，分析实验中的bug）

	sudo apt-get install ros-melodic-plotjuggler

	sudo apt-get install ros-melodic-plotjuggler-ros

	启动：rosrun plotjuggler plotjuggler

四、ulg格式文件转换为csv格式文件：

	1、直接安装pyulog包
	pip install pyulog

	2、在log005.ulg文件目录下运行：
	ulog2csv log005.ulg 


**
使用rosbag录制无人机避障过程，保存下来用plotjuggler分析，
使用QGC连接，从避障开始，使用飞行日志软件分析；


**

五、阿木实验室，PX4基本配置


注意：

1、输出无人机避障总体框架

2、无人机避障系统搭建

3、无人机软件系统设计


-----------------------------------------------------

12.1

一、windows下图片批量编号

#include <iostream>  
#include <io.h>  //对系统文件进行操作的头文件
#include <string>  
#include <sstream>
#include<vector>

using namespace std;

const int N = 6;   //整型格式化输出为字符串后的长度，例如，N=6，则整型转为长度为6的字符串，12转为为000012

const string FileType = ".jpg";    // 需要查找的文件类型

/* 函数说明 整型转固定格式的字符串
输入：
n 需要输出的字符串长度
i 需要结构化的整型
输出：
返回转化后的字符串
*/
string int2string(int n, int i)
{
    char s[BUFSIZ];
    sprintf(s, "%d", i);
    int l = strlen(s);  // 整型的位数

    if (l > n)
    {
        cout << "整型的长度大于需要格式化的字符串长度！";
    }
    else
    {
        stringstream M_num;
        for (int i = 0;i < n - l;i++)
            M_num << "0";
        M_num << i;

        return M_num.str();
    }
}

int main()
{
    _finddata_t c_file;   // 查找文件的类

    string File_Directory ="E:\\image";   //文件夹目录

    string buffer = File_Directory + "\\*" + FileType;

    //long hFile;  //win7系统，_findnext()返回类型可以是long型
    intptr_t hFile;   //win10系统 ，_findnext()返回类型为intptr_t ，不能是long型

    hFile = _findfirst(buffer.c_str(), &c_file);   //找第一个文件

    if (hFile == -1L)   // 检查文件夹目录下存在需要查找的文件
        printf("No %s files in current directory!\n", FileType);
    else
    {
        printf("Listing of files:\n");

        int i = 0;
        string newfullFilePath;
        string oldfullFilePath;
        string str_name;
        do
        {
            oldfullFilePath.clear();
            newfullFilePath.clear();
            str_name.clear();

            //旧名字
            oldfullFilePath = File_Directory + "\\" + c_file.name;

            //新名字
            ++i;
            str_name = int2string(N, i);    //整型转字符串
            newfullFilePath = File_Directory + "\\"+ str_name + FileType;

            /*重命名函数rename（const char* _OldFileName,const char* _NewFileName）
              第一个参数为旧文件路径，第二个参数为新文件路径*/
            int c = rename(oldfullFilePath.c_str(), newfullFilePath.c_str());  

            if (c == 0)
                puts("File successfully renamed");
            else
                perror("Error renaming file");

        } while (_findnext(hFile, &c_file) == 0);  //如果找到下个文件的名字成功的话就返回0,否则返回-1  
        _findclose(hFile);
    }

    return 0;
}

注：修改图片地址和图片格式，直接运行即可

参考：http://t.csdn.cn/b4x2K

****

注意：还是的稠密点云建图，稀疏点云障碍物太不明显


二、录制rosbag以及生成总体框架图

1、当开始录制的时候，无人机PX4出现报错，结束录制后，报错消失；


参考：http://t.csdn.cn/yLPlt


----------------------------------------------------------------------------

12.16

目标：使用激光雷达实现ego-planner



1、启动roslaunch的indoor1.launch时出现报错：

	[gazebo-2] process has died [pid 22088, exit code 255, cmd /opt/ros/melodic/lib/gazebo_ros/gzserver -e ode /home/xcs/PX4_Firmware/Tools/sitl_gazebo/worlds/my_world4.world __name:=gazebo __log:=/home/xcs/.ros/log/80db1420-7d08-11ed-bb47-645d865b3457/gazebo-2.log].
	log file: /home/xcs/.ros/log/80db1420-7d08-11ed-bb47-645d865b3457/gazebo-2*.log

	解决办法：使用Ctrl+C结束当前运行，然后输入

		killall gzserver

		再次roslaunch，问题解决。


2、无人机键盘控制indoor1.launch起飞报错：

	[ERROR] [1671172924.254336491, 1216.593000000]: FCU: Preflight Fail: Position estimate error
	
		更换到indoor3后不报错


--------------------------------------------------------------------------------------------------------------

2023.1.6


一、下载eigen3.4.0

	1、下载地址：http://eigen.tuxfamily.org/index.php?title=Main_Page

	2、cd eigen-3.3.4
	mkdir build
	cd build
	cmake ..
	make
	sudo make install

2023.1.12

二、安装livox

	参考：http://t.csdn.cn/RbfBQl


2.20


一、启动ego-planner自己搭建的室外避障环境时报错：

	[ERROR] [1632398141.557684, 290.045000]: Spawn service failed. Exiting.

	解决办法：source ~/catkin_ws/devel/setup.bash
		1
		再次执行launch文件

		还有问题改下仿真world文件中的仿真时间

		<sim_time>478 56330000</sim_time>
		1
		改为 0
		<sim_time>0</sim_time>

参考：http://t.csdn.cn/MfunW


2/26

一、编译运行R3LIVE

	1、安装livox驱动
	方式一：
	livox-SDK的地址：https://github.com/Livox-SDK/Livox-SDK
	
	方式二：
	git clone https://github.com/Livox-SDK/Livox-SDK.git
	cd Livox-SDK
	cd build && cmake ..
	make
	sudo make install
	
	建议在编译安装完成后进行简答的测试，以确定是否成功安装。
	在build文件夹下，进入sample/lidar或者进入sample/hub文件夹下，运行相应程序进行测试。
	
	命令如下：
	cd sample/lidar
	./lidar_sample
	或者：
	cd sample/hub
	./hub_sample
	
	2、下载编译lovix的ros驱动程序
	（当编译R3live程序时，你会发现，编译是不会通过，并且明确告诉你缺少livox的ros驱动程序，所以，只能安装！）
	  
	  github地址如下：https://github.com/Livox-SDK/livox_ros_driver.git
	  
	   也可以采用官方说明中的终端命令行git clone的方式：

	  git clone https://github.com/Livox-SDK/livox_ros_driver.git ws_livox/src
	  
	 注意：这里是默认创建了ws_livox/src的文件夹，编译安装要在ws_livox文件夹下，
	 当然，也可以改下后面的命令（指“ws_livox/src”）将代码放在自己的文件夹下以便管理。

	 然后就是在ws_livox文件夹（要是自己放在不同的文件夹下记得更改终端下的当前路径信息）下编译：
	 cd ws_livox
	 catkin_make

	 最后是刷新当前ROS包的环境：
	 source ./devel/setup.sh
	 
	3、CGAL和pcl_viewer安装
	 
	官方说明中是一行命令就可以解决了：
	sudo apt-get install libcgal-dev pcl-tools
	 
	4、opencv安装（我安装的是opencv3.4.1）
	
	(1)查看opencv版本：
	pkg-config opencv --modversion
	
	(2)准备opencv3.4.1安装包：
	https://github.com/opencv/opencv/archive/3.4.1.zip
	安装并解压，进入opencv 3.4.文件夹内
	cd opencv-3.4.1
	
	(3)依赖库和cmake安装
	
	在依赖库和cmake的安装之前，先进入管理员权限以此获得更多的权限：
	sudo -s
	
	接下来我们进行cmake的安装：
	sudo apt-get install cmake  
	
	依赖库安装:
	sudo apt-get install build-essential libgtk2.0-dev libavcodec-dev libavformat-dev libjpeg.dev libtiff5.dev libswscale-dev libjasper-dev  

	(4)opencv编译：
	先创建一个编译文件夹并且进入文件夹内：
	mkdir my_build_dir
	
	依次输入命令：
	cmake -D CMAKE_BUILD_TYPE=Release -D CMAKE_INSTALL_PREFIX=/usr/local ..
	make -j4
	sudo make install

	(4)配置opencv库以及配置bash
	sudo gedit /etc/ld.so.conf.d/opencv.conf 
	在末尾添加/usr/local/lib   
	保存
	
	再输入：sudo ldconfig
	opencv库配置完成
	
	(5)接下来配置bash：
	 输入命令：
	 sudo gedit /etc/bash.bashrc  
	同样，在文件末尾添加
	PKG_CONFIG_PATH=$PKG_CONFIG_PATH:/usr/local/lib/pkgconfig
	export PKG_CONFIG_PATH
	点击保存之后关闭
	
	 再输入命令：
	 source /etc/bash.bashrc  
	bash配置完成
	
	最后再进行一次更新即可
	输入命令：
	sudo updatedb  

	(6)opencv的使用--图片特效
	
		1）创建test.cpp文件
		在文件夹opencv-3.4.1下创建并进入mytest文件夹,
		在mytest文件夹下创建一个test.cpp文件并写入代码，
		输入命令：
		mkdir mytest
		即可创建mytest文件夹
		
		输入命令：
		cd mytest
		
		touch test.cpp
		即可进入文件夹并创建文件test.cpp
		
		vim(gedit) test.cpp
		即可打开test.cpp文件编辑
		按I开始在光标处插入
		
		输入代码（注：原博客有误，删去最后一个"}"）：
		#include <opencv2/highgui.hpp>
		#include <opencv2/opencv.hpp>
		using namespace cv;
		using namespace std;
		int main(int argc, char** argv)
		{
			CvPoint center;
			double scale = -3; 

			IplImage* image = cvLoadImage("test1.jpg");
			argc == 2? cvLoadImage(argv[1]) : 0;

			cvShowImage("Image", image);


			if (!image) return -1; 	center = cvPoint(image->width / 2, image->height / 2);
			for (int i = 0;i<image->height;i++)
				for (int j = 0;j<image->width;j++) {
					double dx = (double)(j - center.x) / center.x;
					double dy = (double)(i - center.y) / center.y;
					double weight = exp((dx*dx + dy*dy)*scale);
					uchar* ptr = &CV_IMAGE_ELEM(image, uchar, i, j * 3);
					ptr[0] = cvRound(ptr[0] * weight);
					ptr[1] = cvRound(ptr[1] * weight);
					ptr[2] = cvRound(ptr[2] * weight);
				}

			Mat src;Mat dst;
			src = cvarrToMat(image);
			cv::imwrite("test.png", src);

			cvNamedWindow("test",1);  	imshow("test", src);
			 cvWaitKey();
			 return 0;
		}
		
		按ESC回到命令模式
		输入:wq退出vim编辑器并保存
		
		2)编译文件：
		g++ test.cpp -o test `pkg-config --cflags --libs opencv`
		即可成功编译
		编译语句中-o前后就是将待编译文件名和输出文件名
		而``中包括的就是支持包
		pkg-config:其中pkg-config给出了opencv的头文件和库的所有信息
		我们在安装opencv的时候就会给/usr/lib/目录下，放一个opencv.pc
		我们刚在配置opencv库的时候就放到/usr/local/lib（其中/usr/lib是系统级的,/usr/local/lib是用户级的）这也是为了在使用opencv的时候让系统知道在哪里
		而我们刚才在配置bash的时候用PKG_CONFIG_PATH环境变量所指向的路径下的所有*.pc文件，这就是为什么pkg-config有opencv的头文件和库的所有信息。
		cflags： 指定头文件（.h文件）的路径，如：CFLAGS=-I/usr/include -I/path/include。同样地，安装一个包时会在安装路径下建立一个include目录，当安装过程中出现问题时，试着把以前安装的包的include目录加入到该变量中来。
		所有用opencv的其他程序，在编译时，只需要写pkg-config --cflags --libs opencv,而不需要自己去找opencv的头文件在哪里，要链接的库在哪里。

		3）运行结果：
		在运行之前我们需要给文件夹里放一张名为test1.jpg的图片
		在运行时程序需要调用
		输入命令：
		./test
		成功运行结果
		
		(：如何改变文件（文件夹类型）比如从root类型改为普通类型，常用方法如下：
		常用方法如下：

		sudo chmod 600 ××× (只有所有者有读和写的权限)

		sudo chmod 644 ××× (所有者有读和写的权限，组用户只有读的权限)

		sudo chmod 700 ××× (只有所有者有读和写以及执行的权限)

		sudo chmod 666 ××× (每个人都有读和写的权限)

		sudo chmod 777 ××× (每个人都有读和写以及执行的权限
		其中×××指文件名(也可以是文件夹名，不过要在chmod后加-ld)。

		解释一下，其实整个命令的形式是

		sudo chmod -(代表类型)×××(所有者)×××(组用户)×××(其他用户)

		三位数的每一位都表示一个用户类型的权限设置。取值是0～7，即二进制的[000]~[111]。

		这个三位的二进制数的每一位分别表示读、写、执行权限。

		如000表示三项权限均无，而100表示只读。这样，我们就有了下面的对应：

		0 [000] 无任何权限

		4 [100] 只读权限

		6 [110] 读写权限

		7 [111] 读写执行权限

		现在看上面的几个常用用法就非常清楚了。试着自己来修改权限吧

		最后同时附上查询文件(或文件夹)权限的命令

		ls -l 文件名称 (文件夹将-l改为-ld)。
		参考：https://blog.csdn.net/weixin_39825872/article/details/116602256?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522167741282616800213034497%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fblog.%2522%257D&request_id=167741282616800213034497&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~blog~first_rank_ecpm_v1~rank_v31_ecpm-1-116602256-null-null.blog_rank_default&utm_term=%E6%94%B9%E5%8F%98%E6%96%87%E4%BB%B6%E5%A4%B9root%E6%9D%83%E9%99%90&spm=1018.2226.3001.4450
		)
		)
		
		4)opencv的使用——显示视频
		与上面相同创建一个test1.cpp文件，源码如下(test1.cpp)
		
		编译：
		g++ test1.cpp -o test1 `pkg-config --cflags --libs opencv`
		
		运行：./test1
		
		5)总结：
		通过以上对opencv的系列操作，
		我们使用opencv来给照片加特效，读取本地视频文件，以及打开摄像头显示视频帧等操作，
		了解到了opencv的强大之处。当然如果你感兴趣的话可以再去探索一些，实现更多的操作。
		
		参考链接：https://blog.csdn.net/qq_45999753/articl
		
		
		
		
		     git clone https://github.com/hku-mars/r3live.git
	cd ../
	catkin_make
	source ~/catkin_ws/devel/setup.bash
		
注意：安装过程太慢，考虑有没有别的办法。。。
	
	参考链接1：https://blog.csdn.net/smartfoolish/article/details/122407063?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522167740211216782429751089%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&request_id=167740211216782429751089&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~blog~top_positive~default-1-122407063-null-null.blog_rank_default&utm_term=R3LIVE&spm=1018.2226.3001.4450
	参考链接2：https://blog.csdn.net/handily_1/article/details/122271243?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522167740211216782429751089%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&request_id=167740211216782429751089&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~blog~top_click~default-3-122271243-null-null.blog_rank_default&utm_term=R3LIVE&spm=1018.2226.3001.4450
	

2/28

	1、继续编译R3LIVE，解决报错：
	
		1）error: conflicting declaration ‘typedef struct LZ4_streamDecode_t LZ4_streamDecode_t’
		 typedef struct { unsigned long long table[LZ4_STREAMDECODESIZE_U64]; } LZ4_streamDecode_t;
		 
		 解决办法：sudo mv /usr/include/flann/ext/lz4.h /usr/include/flann/ext/lz4.h.bak
				 sudo mv /usr/include/flann/ext/lz4hc.h /usr/include/flann/ext/lz4.h.bak

				 sudo ln -s /usr/include/lz4.h /usr/include/flann/ext/lz4.h
				 sudo ln -s /usr/include/lz4hc.h /usr/include/flann/ext/lz4hc.h

	参考：https://blog.csdn.net/RuningLING/article/details/119419078
	
		2）opencv版本冲突
		/usr/bin/ld: warning: libopencv_imgproc.so.3.4, needed by /usr/local/lib/libopencv_calib3d.so.3.4.1, may conflict with libopencv_imgproc.so.3.2
		/usr/bin/ld: warning: libopencv_core.so.3.4, needed by /usr/local/lib/libopencv_calib3d.so.3.4.1, may conflict with libopencv_core.so.3.2
		/usr/bin/ld: warning: libopencv_imgcodecs.so.3.4, needed by /usr/local/lib/libopencv_highgui.so.3.4.1, may conflict with libopencv_imgcodecs.so.3.2

		解决办法：
				
				locate 缺少的lib文件

				locate libopencv_highgui.so.3.4

				进入编译器lib目录

				cd /usr/lib/x86_64-linux-gnu

				建立软链接

				sudo ln -s /home/yzh/opencv-3.4/lib/libopencv_highgui.so.3.4
				
			参考：https://blog.csdn.net/Thinkin9/article/details/122413384
			
		解完报错后，运行成功！
		
		
3/1


	1、运行r3live运行过程中一直卡顿，生成的pcd点云文件会存在覆盖；
	
	2、
		
		

3.4

1、安装Google浏览器

    1）打开终端（Terminal）。
    输入以下命令来下载谷歌浏览器的安装文件：

	wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb

    2）下载完成后，运行以下命令以安装下载的文件：
	sudo dpkg -i google-chrome-stable_current_amd64.deb

    3）如果提示缺少依赖项，则运行以下命令来安装它们：
	sudo apt-get install -f

    安装完成后，在应用程序菜单中可以找到并打开谷歌浏览器。
	
	、配置激光雷达（rplidar s1 ）

2、配置激光雷达（rplidar s1 ），在Rviz上显示点云图

	1)创建工作空间：
	mkdir -p ~/catkin_ws/src
	cd ~/catkin_ws/
	#如果使用python2直接catkin_make
	#catkin_make
	#python3用户
	#这将会配置 catkin_make 使用 Python 3.你可以在随后的构建中只使用 catkin_make。
	catkin_make -DPYTHON_EXECUTABLE=/usr/bin/python3


	2)安装配置rplidar-s1

	在工作空间的src下面下载官网ROS包
	git clone https://github.com/Slamtec/rplidar_ros.git

	#在~/catkin_ws目录下编译
	catkin_make

	检查rplidar的串行端口的权限：
	ls -l /dev | grep ttyUSB

	添加写权限：（例如/dev/ttyUSB0）
	sudo chmod 666 /dev/ttyUSB0

	启动一个rplidar节点并在rviz中查看扫描结果。
	#记得启动之前启动roscore
	source devel/setup.bash
	roslaunch rplidar_ros view_rplidar_s1.launch
	
3、RPLIDAR在Rviz上渲染显示周围环境

	1）hector_mapping包安装
	sudo apt-get install ros-melodic-hector-slam

	2）创建launch文件， 在rplidar_ros/launch/目录下添加hector_mapping_demo.launch文件
	vim（gedit）  hector_mapping_demo.launch

		<launch>


	  <node pkg="hector_mapping" type="hector_mapping" name="hector_mapping" output="screen">
		<!-- Frame names -->
		<param name="pub_map_odom_transform" value="true"/>
		<param name="map_frame" value="map" />
		<param name="base_frame" value="base_link" />
		<param name="odom_frame" value="base_link" />


		<!-- Tf use -->
		<param name="use_tf_scan_transformation" value="true"/>
		<param name="use_tf_pose_start_estimate" value="false"/>


		<!-- Map size / start point -->
		<param name="map_resolution" value="0.05"/>
		<param name="map_size" value="2048"/>
		<param name="map_start_x" value="0.5"/>
		<param name="map_start_y" value="0.5" />
		<param name="laser_z_min_value" value = "-1.0" />
		<param name="laser_z_max_value" value = "1.0" />
		<param name="map_multi_res_levels" value="2" />


		<param name="map_pub_period" value="2" />
		<param name="laser_min_dist" value="0.4" />
		<param name="laser_max_dist" value="5.5" />
		<param name="output_timing" value="false" />
		<param name="pub_map_scanmatch_transform" value="true" />
		<!--<param name="tf_map_scanmatch_transform_frame_name" value="scanmatcher_frame" />-->
	<!-- Map update parameters -->
		<param name="update_factor_free" value="0.4"/>
		<param name="update_factor_occupied" value="0.7" />
		<param name="map_update_distance_thresh" value="0.2"/>
		<param name="map_update_angle_thresh" value="0.06" />


		<!-- Advertising config -->
		<param name="advertise_map_service" value="true"/>
		<param name="scan_subscriber_queue_size" value="5"/>
		<param name="scan_topic" value="scan"/>
	  </node>


	  <node pkg="rplidar_ros" type="rplidarNode" name="rplidarNode" output="screen">
		<param name="serial_port"         type="string" value="/dev/ttyUSB0"/>
		<param name="serial_baudrate"     type="int"    value="265000"/>
		<param name="frame_id"            type="string" value="laser"/>
		<param name="inverted"            type="bool"   value="false"/>
		<param name="angle_compensate"    type="bool"   value="true"/>
	  </node>


	  <node pkg="tf" type="static_transform_publisher" name="base_to_laser_broadcaster" args="0 0 0 0 0 0 /base_link /laser 100"/>
	  <node pkg="rviz" type="rviz" name="rviz" args="-d $(find hector_slam_launch)/rviz_cfg/mapping_demo.rviz"/>


	</launch>
	
	（注意：如果使用的激光雷达,不是rplidar_s1,而是rplidar_s2 ,要修改波特率，修改为1000000）

	catkin_make编译完成后记得source
	source devel/setup.bash 

	3）启动launch文件
	roslaunch rplidar_ros hector_mapping_demo.launch
	
	如果要保存地图的话
	我们需要使用map_server软件包里的map_saver来保存当前的地图，首先需要保证已经安装了map_server软件包，安装命令如下：
	sudo apt-get install ros-melodic-map-server
   
	当安装好map_server后，接下来就可以使用如下命令来保存地图了，在stdr_gmapping的maps目录下执行命令如下：
	rosrun map_server map_saver map:=/hector_map -f mymap

参考链接：https://blog.csdn.net/qq_40695642/article/details/108137300?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522167791570216782427488582%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fall.%2522%257D&request_id=167791570216782427488582&biz_id=&utm_medium=distribute.pc_search_result.none-task-code-2~all~first_rank_ecpm_v1~rank_v31_ecpm-1-108137300-5-null-null.142^v73^insert_down4,201^v4^add_ask,239^v2^insert_chatgpt&utm_term=rplidar%20s1
	
	
4、配置编译dyn_small_obs_avoidance（空中机器人利用机载电脑感知计算躲避动态小障碍物）


	1）Build
	
	Clone the repository and catkin_make:
    cd ~/catkin_ws/src
    git clone https://github.com/hku-mars/dyn_small_obs_avoidance.git
    cd ..
    catkin_make

	2）Run demo
	
	2.1)Start program
    source devel/setup.bash
    roslaunch path_planning demo.launch 

	2.2)Run rosbag or directly fly
	You can download our demos rosbag from https://drive.google.com/drive/folders/1knQwnrbwunGIvXzOL6wWKkCtOkGE22bG?usp=sharing And play the bag by:

    rosbag play XXX.bag

	2.3)Set target point

    rostopic pub /goal geometry_msgs/PoseStamped '{header: {stamp: now, frame_id: "camera_init"}, pose: {position: {x: 5.0, y: 0.0, z: 1.0}, orientation: {w: 1.0}}}'

	You can change the target point by setting different value of 'x','y','z' in the above command.
	
	3)Run with other equipments

	You can also run this planning program as a module with other point cloud input from other sensors 
	(like depth camera D435i). But we have not yet test it on depth cameras. 
	First, change the point cloud topic to your point cloud topic name in path_planning/launch/demo_withNOlidar.launch

    <remap from='/your_pointcloud_topic' to='/cloud_registered'/> 

	Then, start the program:

    source devel/setup.bash
    roslaunch path_planning demo_withNOlidar.launch 

参考链接：https://github.com/hku-mars/dyn_small_obs_avoidance

5、配置编译realsense D435i相机

	见 Ji_Lu_tx.txt

参考：	https://blog.csdn.net/YOULANSHENGMENG/article/details/125334427?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522167792882216782427449507%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&request_id=167792882216782427449507&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_positive~default-1-125334427-null-null.142^v73^insert_down4,201^v4^add_ask,239^v2^insert_chatgpt&utm_term=realsense%20d435i&spm=1018.2226.3001.4187
	
	
	
	
	
	
	
	
	
	




		

		
		

		

		

	

	
